{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9192d712",
   "metadata": {},
   "source": [
    "# 贝叶斯公式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329acbf3",
   "metadata": {},
   "source": [
    "𝑃(𝐴|𝐵)=𝑃(𝐵|𝐴)𝑃(𝐴)𝑃(𝐵)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae28016c",
   "metadata": {},
   "source": [
    "## 示例一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8695b759",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T11:24:22.294783Z",
     "start_time": "2022-05-06T11:24:22.273338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 假设已经抽出红球为事件 B，\n",
    "# 选中容器 A 为事件 A，\n",
    "# 则有：P(B) = 8/20，P(A) = 1/2，\n",
    "# 从A容器中选中红球的概率：P(B|A) = 7/10，按照公式，则有：\n",
    "\n",
    "# 选中了球是红球，请问来自A容器的概率是多少\n",
    "# P(A|B) = P(B|A)*P(A)/P(B) = (7/10)*(1/2)/(8/20) = 0.875\n",
    "\n",
    "np.round(7/10 * 1/2 /(8/20),3) # 7/8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b532e7",
   "metadata": {},
   "source": [
    "## 示例二"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2349d451",
   "metadata": {},
   "source": [
    "例如：一座别墅在过去的 20 年里一共发生过 2 次被盗，\n",
    "别墅的主人有一条狗，狗平均每周晚上叫 3 次，\n",
    "在盗贼入侵时狗叫的概率被估计为 0.9，问题是：在狗叫的时候发生入侵的概率是多少？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bade441d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T11:25:51.770462Z",
     "start_time": "2022-05-06T11:25:51.757059Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00058"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 被盗，事件A P(A) = 2/(20 * 365)\n",
    "# 狗叫，事件B P(B) = 3/7\n",
    "# 盗贼入侵狗叫 P(B|A) = 0.9\n",
    "\n",
    "# 狗叫时发生入侵 P(A|B) = P(B|A) * P(A)/P(B)\n",
    "np.round(0.9 * 2/(20 * 365)/(3/7),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c92df38",
   "metadata": {},
   "source": [
    "# 三种贝叶斯模型使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16122d45",
   "metadata": {},
   "source": [
    "## 高斯分布的朴素贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d382845",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T11:27:16.915726Z",
     "start_time": "2022-05-06T11:27:16.150846Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "# navie 天真，朴素\n",
    "from sklearn.naive_bayes import GaussianNB # 高斯NB，Naive Bayes\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 自然界中鸢尾花，自然属性，符合正态分布\n",
    "# 花萼长宽，花瓣长宽\n",
    "X,y = datasets.load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45cdc1bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T11:28:33.437730Z",
     "start_time": "2022-05-06T11:28:32.875751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "高斯朴素贝叶斯算法平均预测准确率是： 0.9534999999999985\n"
     ]
    }
   ],
   "source": [
    "# 正太分布，属性\n",
    "score = 0\n",
    "model = GaussianNB()\n",
    "for i in range(1000):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "    model.fit(X_train,y_train)\n",
    "    score += model.score(X_test,y_test)/1000\n",
    "print('高斯朴素贝叶斯算法平均预测准确率是：',score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d25a2cc",
   "metadata": {},
   "source": [
    "## 伯努利分布朴素贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3af4266",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T11:29:26.483710Z",
     "start_time": "2022-05-06T11:29:25.932786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "伯努利分布素贝叶斯算法平均预测准确率是： 0.26752631578947483\n"
     ]
    }
   ],
   "source": [
    "# 你想，我们的数据特征分布，是二项分布？？？\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "score = 0\n",
    "model = BernoulliNB()\n",
    "for i in range(1000):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "    model.fit(X_train,y_train)\n",
    "    score += model.score(X_test,y_test)/1000\n",
    "print('伯努利分布素贝叶斯算法平均预测准确率是：',score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1039ca",
   "metadata": {},
   "source": [
    "## 多项式分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ba73fa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T11:29:59.373320Z",
     "start_time": "2022-05-06T11:29:58.890404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多项式分布朴素贝叶斯算法平均预测准确率是： 0.8154473684210523\n"
     ]
    }
   ],
   "source": [
    "# 植物，数据，符合多项式分布\n",
    "# 人身高：离散，极矮、矮、中等、高、特别高（满足多项分布）\n",
    "# 多项分布 和 高斯分布，一定的类似\n",
    "from sklearn.naive_bayes import MultinomialNB # 二项分布的延伸\n",
    "score = 0\n",
    "model = MultinomialNB()\n",
    "for i in range(1000):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "    model.fit(X_train,y_train)\n",
    "    score += model.score(X_test,y_test)/1000\n",
    "print('多项式分布朴素贝叶斯算法平均预测准确率是：',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33d12e8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T11:30:17.535038Z",
     "start_time": "2022-05-06T11:30:17.514982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc1a8f",
   "metadata": {},
   "source": [
    "# 文本分类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a15282",
   "metadata": {},
   "source": [
    "## 英文one-hot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de10f06e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T11:31:23.191265Z",
     "start_time": "2022-05-06T11:31:23.169113Z"
    }
   },
   "outputs": [],
   "source": [
    "# jieba分词，中国人写的Python库\n",
    "# 一句话，分成一个个词\n",
    "import jieba # pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf66b391",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T11:33:34.274683Z",
     "start_time": "2022-05-06T11:33:33.681215Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/jt/qjpzhhld5znczz2yp8zyt7xw0000gn/T/jieba.cache\n",
      "Loading model cost 0.582 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['My', 'Precision', 'are', 'ate', 'cat', 'dog', 'few', 'fish',\n",
       "       'homework', 'in', 'is', 'my', 'only', 'reason', 'that', 'the',\n",
       "       'there', 'things', 'very', 'world', 'you'], dtype='<U9')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ['My dog ate my homework.',\n",
    "        'My cat ate the fish.',\n",
    "        'Precision things are very few in the world,that is the reason there is only you!']\n",
    "\n",
    "result = []\n",
    "for s in data:\n",
    "    result.extend([i for i in jieba.lcut(s) if i not in [' ',',','.','!']])\n",
    "    \n",
    "result = np.array(result)\n",
    "result = np.unique(result) # 去重\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92e3226e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T11:34:24.536311Z",
     "start_time": "2022-05-06T11:34:24.520782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My', ' ', 'dog', ' ', 'ate', ' ', 'my', ' ', 'homework', '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.lcut('My dog ate my homework.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95884243",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T11:36:54.539162Z",
     "start_time": "2022-05-06T11:36:54.519244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My dog ate my homework.\n",
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "My cat ate the fish.\n",
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "Precision things are very few in the world,that is the reason there is only you!\n",
      "[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# 词向量转换，一个个句子，进行转换\n",
    "# 每个句子中一个个词，进行转换\n",
    "for s in data:\n",
    "    sentense = [i for i in jieba.lcut(s) if i not in [' ',',','.','!']]\n",
    "    \n",
    "    # 嵌入，词嵌入\n",
    "    # 词，向量化，数字化\n",
    "    word_embeding = [(word == result).astype(np.int8) for word in sentense]\n",
    "    print(s)\n",
    "    print(np.array(word_embeding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bc6e6c",
   "metadata": {},
   "source": [
    "## 中文one-hot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72148203",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T11:43:08.776095Z",
     "start_time": "2022-05-06T11:43:08.767186Z"
    }
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "233fca02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T11:43:24.214728Z",
     "start_time": "2022-05-06T11:43:24.197987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['喜欢',\n",
       " '上',\n",
       " '一个',\n",
       " '人',\n",
       " '尼姑',\n",
       " '亲吻',\n",
       " '了',\n",
       " '和尚',\n",
       " '的',\n",
       " '嘴巴',\n",
       " '老师',\n",
       " '你',\n",
       " '教',\n",
       " '的',\n",
       " '都',\n",
       " '是',\n",
       " '没用',\n",
       " '的',\n",
       " '东西']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 和尚的嘴巴亲吻了尼姑\n",
    "data = ['喜欢上一个人','尼姑亲吻了和尚的嘴巴','老师你教的都是没用的东西']\n",
    "result = []\n",
    "\n",
    "for s in data:\n",
    "    result.extend([word for word in jieba.lcut(s)])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f34b5c00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T11:43:45.675639Z",
     "start_time": "2022-05-06T11:43:45.662031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['一个', '上', '东西', '了', '亲吻', '人', '你', '和尚', '喜欢', '嘴巴', '尼姑', '教',\n",
       "       '是', '没用', '的', '老师', '都'], dtype='<U2')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 去重,字典\n",
    "result = np.unique(np.array(result))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "718ba4fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T11:47:19.875204Z",
     "start_time": "2022-05-06T11:47:19.858874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "喜欢上一个人\n",
      "[[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "尼姑亲吻了和尚的嘴巴\n",
      "[[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]]\n",
      "老师你教的都是没用的东西\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "for s in data:\n",
    "    sentence = jieba.lcut(s)\n",
    "    # 词向量，数组，表示每一句话\n",
    "    word_embedding = [(word == result).astype(np.int8) for word in sentence]\n",
    "    print(s,np.array(word_embedding),sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10b0788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "324px",
    "left": "1358px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
