{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e60de481",
   "metadata": {},
   "source": [
    "# datasets基本使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "409aa337",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T06:49:31.675478Z",
     "start_time": "2022-05-30T06:49:22.910067Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90e2eee",
   "metadata": {},
   "source": [
    "## 从元组, 列表, 字典, ndarray中创建dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da3af271",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T06:50:21.937830Z",
     "start_time": "2022-05-30T06:50:20.844575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 所有数据集相关的内容都在tf.data中\n",
    "# from_tensor_slices,可以从元组, 列表, 字典, ndarray中创建dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices(np.arange(10))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7a10670",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T06:51:01.365514Z",
     "start_time": "2022-05-30T06:51:01.321512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 数据集最基础的用法就是取数据\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0342b7fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T06:54:30.889672Z",
     "start_time": "2022-05-30T06:54:30.875475Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据集重复3次\n",
    "# 如果不指定重复次数, 默认是无限循环.\n",
    "dataset = dataset.repeat(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "592b902c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T06:56:58.422652Z",
     "start_time": "2022-05-30T06:56:58.389381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcd42aa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T06:58:57.778355Z",
     "start_time": "2022-05-30T06:58:57.740008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
      "tf.Tensor([8 9 0 1 2 3 4], shape=(7,), dtype=int32)\n",
      "tf.Tensor([5 6 7 8 9 0 1], shape=(7,), dtype=int32)\n",
      "tf.Tensor([2 3 4 5 6 7 8], shape=(7,), dtype=int32)\n",
      "tf.Tensor([9 0 1 2 3 4 5], shape=(7,), dtype=int32)\n",
      "tf.Tensor([6 7 8 9 0 1 2], shape=(7,), dtype=int32)\n",
      "tf.Tensor([3 4 5 6 7 8 9], shape=(7,), dtype=int32)\n",
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9], shape=(6,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 重复三次, 每批数据取7个.\n",
    "dataset = dataset.repeat(3).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "286e4b0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T07:02:53.002326Z",
     "start_time": "2022-05-30T07:02:52.981862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2] cat\n",
      "[3 4] dog\n",
      "[5 6] fox\n"
     ]
    }
   ],
   "source": [
    "# 从元组创建dataset, (x,y)\n",
    "x = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "y = np.array(['cat', 'dog', 'fox'])\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "for item_x, item_y in dataset:\n",
    "    print(item_x.numpy(), item_y.numpy().decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdc8bf5",
   "metadata": {},
   "source": [
    "字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2e27c90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T07:05:39.463348Z",
     "start_time": "2022-05-30T07:05:39.448421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2] b'cat'\n",
      "[3 4] b'dog'\n",
      "[5 6] b'fox'\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices({\n",
    "    'feature': x,\n",
    "    'label': y\n",
    "})\n",
    "for item in dataset:\n",
    "    print(item['feature'].numpy(), item['label'].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f95880b",
   "metadata": {},
   "source": [
    "## interleave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26ee6fa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T07:08:06.065182Z",
     "start_time": "2022-05-30T07:08:05.933263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# interleave\n",
    "# 最常见用法 : 文件名dataset  --> 具体数据集\n",
    "dataset = tf.data.Dataset.from_tensor_slices(np.arange(10))\n",
    "dataset = dataset.repeat(3).batch(7)\n",
    "# map_fn, cycle_length 并行长度, block_length \n",
    "dataset = dataset.interleave(\n",
    "    lambda v: tf.data.Dataset.from_tensor_slices(v),\n",
    "    cycle_length = 5,\n",
    "    block_length = 5\n",
    ")\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ba55e8",
   "metadata": {},
   "source": [
    "# 生成csv文件和读取csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03929235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T07:10:33.712322Z",
     "start_time": "2022-05-30T07:10:33.702893Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed8d97ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T07:11:00.404647Z",
     "start_time": "2022-05-30T07:10:59.462594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8) (11610,)\n",
      "(3870, 8) (3870,)\n",
      "(5160, 8) (5160,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# 切割数据\n",
    "# 训练数据, 验证集, 测试数据\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(housing.data, housing.target, random_state=7)\n",
    "# 从x_train_all中切割出训练数据和校验数据\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_all, y_train_all, random_state=11)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "# 标准化处理\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.transform(x_valid)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d2a73af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T07:11:36.144777Z",
     "start_time": "2022-05-30T07:11:36.128923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.80154431,  0.27216142, -0.11624393, ..., -0.02103962,\n",
       "        -0.58976206, -0.08241846],\n",
       "       [-0.29807281,  0.35226166, -0.10920508, ..., -0.006034  ,\n",
       "         1.08055484, -1.06113817],\n",
       "       [-0.03058829, -0.92934213,  0.25962148, ..., -0.03077987,\n",
       "         1.59844639, -1.81515182],\n",
       "       ...,\n",
       "       [-1.11006415, -1.40994355, -0.57897311, ..., -0.14407844,\n",
       "         1.76174553, -2.13473376],\n",
       "       [ 0.32465459,  0.27216142, -0.10777932, ..., -0.06074976,\n",
       "        -0.65508172,  0.64662786],\n",
       "       [-0.10982126, -0.52884094,  0.25735571, ..., -0.04351442,\n",
       "        -1.14497913,  1.17094199]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2310241d",
   "metadata": {},
   "source": [
    "如何使用tensorflow去批量读取csv文件. 把csv的内容汇总成一个大的数据集.\n",
    "\n",
    "1. 生成csv文件.\n",
    "\n",
    "2. 读取csv文件.\n",
    "\n",
    "3. 解析字段.\n",
    "\n",
    "4. 变成dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6573cfd",
   "metadata": {},
   "source": [
    "## 生成csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cf1ca4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T08:06:16.509842Z",
     "start_time": "2022-05-30T08:06:16.492362Z"
    }
   },
   "outputs": [],
   "source": [
    "# 生成csv文件.\n",
    "# 创建目录存放csv文件.\n",
    "import os\n",
    "\n",
    "output_dir = 'generate_csv'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "def save_to_csv(output_dir,data,name_prefix,header = None,n_parts =10):\n",
    "    # 生成csv的文件名\n",
    "    path_format = os.path.join(output_dir,'{}_{:02d}.csv') \n",
    "    filenames = []\n",
    "    \n",
    "    for file_idx,row_indices in enumerate(\n",
    "        np.array_split(np.arange(len(data)),n_parts)):\n",
    "        # 每一个csv的文件名\n",
    "        part_csv = path_format.format(name_prefix,file_idx)\n",
    "        filenames.append(part_csv)\n",
    "        \n",
    "        # 取数据，写到文件中\n",
    "        with open(part_csv,'wt',encoding='utf-8') as f:\n",
    "            if header is not None:\n",
    "                f.write(header + '\\n')\n",
    "            for row_index  in row_indices:\n",
    "                f.write(','.join([repr(col) for col in data[row_index]]))\n",
    "                f.write('\\n')\n",
    "    return filenames        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8521ad83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T08:08:28.277936Z",
     "start_time": "2022-05-30T08:08:28.259320Z"
    }
   },
   "outputs": [],
   "source": [
    "# 依次生成训练数据, 校验数据和测试数据的csv文件\n",
    "# 把样本数据和对应的标记数据合并到一起.\n",
    "train_data = np.c_[x_train_scaled, y_train]\n",
    "valid_data = np.c_[x_valid_scaled, y_valid]\n",
    "test_data = np.c_[x_test_scaled, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "004fd234",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T08:09:09.763755Z",
     "start_time": "2022-05-30T08:09:09.756616Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "945ccdff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T08:09:49.326723Z",
     "start_time": "2022-05-30T08:09:49.319474Z"
    }
   },
   "outputs": [],
   "source": [
    "# 处理header\n",
    "header_cols = housing.feature_names + ['MedianHouseValue']\n",
    "header_str = ','.join(header_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6faa5b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T08:12:19.461764Z",
     "start_time": "2022-05-30T08:12:19.450684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude',\n",
       " 'MedianHouseValue']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18c0ea55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T08:12:56.460241Z",
     "start_time": "2022-05-30T08:12:56.445641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MedInc,HouseAge,AveRooms,AveBedrms,Population,AveOccup,Latitude,Longitude,MedianHouseValue'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38374cff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T08:13:59.717177Z",
     "start_time": "2022-05-30T08:13:59.165399Z"
    }
   },
   "outputs": [],
   "source": [
    "# 生成csv文件\n",
    "train_filenames = save_to_csv(output_dir, train_data, 'train', header_str, n_parts=20)\n",
    "valid_filenames = save_to_csv(output_dir, valid_data, 'valid', header_str, n_parts=20)\n",
    "test_filenames = save_to_csv(output_dir, test_data, 'test', header_str, n_parts=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2baa2940",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T08:15:28.608768Z",
     "start_time": "2022-05-30T08:15:28.591649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 11607, 11608, 11609])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(len(x_train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23f87aa0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T08:15:44.292548Z",
     "start_time": "2022-05-30T08:15:44.277654Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19]),\n",
       " array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39]),\n",
       " array([40, 41, 42, 43, 44, 45, 46, 47, 48, 49]),\n",
       " array([50, 51, 52, 53, 54, 55, 56, 57, 58, 59]),\n",
       " array([60, 61, 62, 63, 64, 65, 66, 67, 68, 69]),\n",
       " array([70, 71, 72, 73, 74, 75, 76, 77, 78, 79]),\n",
       " array([80, 81, 82, 83, 84, 85, 86, 87, 88, 89]),\n",
       " array([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_split(np.arange(100), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab6a6396",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T08:16:28.270880Z",
     "start_time": "2022-05-30T08:16:28.256860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([   0,    1,    2, ..., 1158, 1159, 1160]),\n",
       " array([1161, 1162, 1163, ..., 2319, 2320, 2321]),\n",
       " array([2322, 2323, 2324, ..., 3480, 3481, 3482]),\n",
       " array([3483, 3484, 3485, ..., 4641, 4642, 4643]),\n",
       " array([4644, 4645, 4646, ..., 5802, 5803, 5804]),\n",
       " array([5805, 5806, 5807, ..., 6963, 6964, 6965]),\n",
       " array([6966, 6967, 6968, ..., 8124, 8125, 8126]),\n",
       " array([8127, 8128, 8129, ..., 9285, 9286, 9287]),\n",
       " array([ 9288,  9289,  9290, ..., 10446, 10447, 10448]),\n",
       " array([10449, 10450, 10451, ..., 11607, 11608, 11609])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_split(np.arange(len(x_train_scaled)), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7263378d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T08:17:11.291061Z",
     "start_time": "2022-05-30T08:17:11.278699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['generate_csv\\\\train_00.csv',\n",
       " 'generate_csv\\\\train_01.csv',\n",
       " 'generate_csv\\\\train_02.csv',\n",
       " 'generate_csv\\\\train_03.csv',\n",
       " 'generate_csv\\\\train_04.csv',\n",
       " 'generate_csv\\\\train_05.csv',\n",
       " 'generate_csv\\\\train_06.csv',\n",
       " 'generate_csv\\\\train_07.csv',\n",
       " 'generate_csv\\\\train_08.csv',\n",
       " 'generate_csv\\\\train_09.csv',\n",
       " 'generate_csv\\\\train_10.csv',\n",
       " 'generate_csv\\\\train_11.csv',\n",
       " 'generate_csv\\\\train_12.csv',\n",
       " 'generate_csv\\\\train_13.csv',\n",
       " 'generate_csv\\\\train_14.csv',\n",
       " 'generate_csv\\\\train_15.csv',\n",
       " 'generate_csv\\\\train_16.csv',\n",
       " 'generate_csv\\\\train_17.csv',\n",
       " 'generate_csv\\\\train_18.csv',\n",
       " 'generate_csv\\\\train_19.csv']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a722bf8e",
   "metadata": {},
   "source": [
    "1. filenames -> dataset\n",
    "2. read file -> dataset -> datasets -> merge\n",
    "3. parse csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd744513",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T08:18:26.374394Z",
     "start_time": "2022-05-30T08:18:26.331325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'generate_csv\\\\train_18.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_13.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_08.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_00.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_05.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_19.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_11.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_03.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_12.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_17.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_15.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_07.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_04.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_16.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_02.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_10.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_06.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_14.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_09.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'generate_csv\\\\train_01.csv', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# tf.data.Dataset.list_files可以从文件名列表中生成dataset\n",
    "filename_dataset = tf.data.Dataset.list_files(train_filenames)\n",
    "for filename in filename_dataset:\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4529eb91",
   "metadata": {},
   "source": [
    "# 读取csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3836e80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T08:20:39.730154Z",
     "start_time": "2022-05-30T08:20:39.635277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'0.04971034572063198,-0.8492418886278699,-0.06214699417830008,0.17878747064657746,-0.8025354230744277,0.0005066066922077538,0.6466457006743215,-1.1060793768010604,2.286'\n",
      "b'-1.0775077698160966,-0.44874070548966555,-0.5680568205591913,-0.14269262164909954,-0.09666677138213985,0.12326468238687088,-0.3144863716683942,-0.4818958888413162,0.978'\n",
      "b'0.401276648075221,-0.9293421252555106,-0.05333050451405854,-0.1865945262276826,0.6545661895448709,0.026434465728210874,0.9312527706398824,-1.4406417263474771,2.512'\n",
      "b'0.42408210084996534,0.9129633171802288,-0.04437481876046234,-0.15297213746739335,-0.24727627804141977,-0.10539166599677323,0.8612674255663844,-1.3357789003702432,3.955'\n",
      "b'0.09734603446040174,0.7527628439249472,-0.20218964416999152,-0.1954700015215477,-0.4060513603629498,0.006785531677655949,-0.813715166526018,0.656614793197258,1.119'\n",
      "b'-1.453851024367546,1.874166156711919,-1.1315714708271856,0.3611276016530489,-0.3978857847006997,-0.03273859332533962,-0.7390641317809511,0.646627857389904,1.875'\n",
      "b'-1.2310715896684647,0.9129633171802288,-0.19194563416838628,0.1285146301786722,-0.18739538985158558,0.1460427975617358,-0.7857210284966175,0.656614793197258,0.953'\n",
      "b'-0.8757754235423053,1.874166156711919,-0.9487499555702599,-0.09657184824705009,-0.7163432355284542,-0.07790191228558485,0.9825753570271144,-1.4206678547327694,2.75'\n",
      "b'0.4369234889778008,-1.9706452014148417,-0.1664210569911193,0.05486205164394496,-0.8379195842775115,-0.1323988058685803,-0.9956770637171147,0.941242463706905,1.73'\n",
      "b'-1.4803330571456954,-0.6890414153725881,-0.35624704887282904,-0.1725588908792445,-0.8215884329530113,-0.1382309124854157,1.9157132913404298,-1.0211904224385344,0.928'\n",
      "b'-1.1179501498535522,0.3522616607867429,-0.17415480367337632,0.1029357335256435,-0.24364713330264193,-0.06195252491676357,1.9063819119972951,-1.1210597805120879,0.603'\n",
      "b'-0.47966389100153284,1.874166156711919,0.0560470563410166,-0.006849812286680542,0.02944600829038973,-0.12115399093152514,1.0338979434143465,-1.3407723682739239,2.895'\n",
      "b'0.7751155655229017,1.874166156711919,0.15645971958808144,-0.18905190538070707,-0.6292437617977863,-0.08791603438866835,-0.7483955111240856,0.5717258388347319,4.851'\n",
      "b'-0.49303811681102094,-1.5701440182766375,-0.6933897788607161,0.16277645579446545,0.3279431630548662,-0.08806528786307917,-0.86503775291325,0.6366409215825501,2.033'\n",
      "b'0.21174628471128154,1.1532640270631513,-0.2507761334605016,-0.2564987121705146,-0.6473894854916754,0.017590216427099285,0.7959477701644521,-1.1510205879341566,1.935'\n"
     ]
    }
   ],
   "source": [
    "# 对filename_dataset中的每一个文件进行读取\n",
    "n_readers = 5\n",
    "dataset = filename_dataset.interleave(\n",
    "    # map_fn\n",
    "    # skip(1)跳过第一行.\n",
    "    lambda filename: tf.data.TextLineDataset(filename).skip(1),\n",
    "    cycle_length = n_readers,\n",
    ")\n",
    "for line in dataset.take(15):\n",
    "    print(line.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bbee76b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T08:25:55.224014Z",
     "start_time": "2022-05-30T08:25:55.211169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=int32, numpy=3>, <tf.Tensor: shape=(), dtype=int32, numpy=4>, <tf.Tensor: shape=(), dtype=int32, numpy=5>]\n"
     ]
    }
   ],
   "source": [
    "# 解析csv\n",
    "# b'-1.1157655153587753,0.9930635538078697,-0.33419201318312125,-0.0653521844775239,-0.3289320346639209,0.04343065774347637,-0.12785878480573185,0.30707203993980686,0.524'\n",
    "# tensorflow中解析csv文件的api: tf.io.decode_csv()\n",
    "# 注意: csv中的字段个数和record_defaults中的个数必须一一对应, 不能多, 不能少.\n",
    "sample_str = '1,2,3,4,5'\n",
    "# 字段对应的类型\n",
    "record_defaults = [tf.constant(0, dtype=tf.int32)] * 5\n",
    "# record_defaults = [\n",
    "#     tf.constant(0, dtype=tf.int32),\n",
    "#     0,\n",
    "#     np.nan,\n",
    "#     'hello',\n",
    "#     tf.constant([])\n",
    "# ]\n",
    "# print(record_defaults)\n",
    "parsed_fields = tf.io.decode_csv(sample_str, record_defaults)\n",
    "print(parsed_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "effb5e4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T08:27:40.102876Z",
     "start_time": "2022-05-30T08:27:40.087917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([1, 2, 3, 4, 5])>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.stack(parsed_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb86709b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T08:28:27.724233Z",
     "start_time": "2022-05-30T08:28:27.705129Z"
    }
   },
   "outputs": [],
   "source": [
    "# 封装解析一行csv的函数\n",
    "def parse_csv_line(line, n_fields=9):\n",
    "    record_defaults = [tf.constant(np.nan)] * n_fields\n",
    "    parsed_fields = tf.io.decode_csv(line, record_defaults)\n",
    "    x = tf.stack(parsed_fields[0:-1])\n",
    "    y = tf.stack(parsed_fields[-1:])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "198c1a70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T08:34:10.579874Z",
     "start_time": "2022-05-30T08:34:10.563589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       " array([-1.1157656 ,  0.99306357, -0.334192  , -0.06535219, -0.32893205,\n",
       "         0.04343066, -0.12785879,  0.30707204], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.524], dtype=float32)>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_csv_line(b'-1.1157655153587753,0.9930635538078697,-0.33419201318312125,-0.0653521844775239,-0.3289320346639209,0.04343065774347637,-0.12785878480573185,0.30707203993980686,0.524')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97393d6",
   "metadata": {},
   "source": [
    "## 上面的功能全部封装到一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f0dedb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T08:34:53.115820Z",
     "start_time": "2022-05-30T08:34:53.103421Z"
    }
   },
   "outputs": [],
   "source": [
    "# 把上面的功能全部封装到一起\n",
    "def csv_reader_dataset(filenames, n_readers=5, \n",
    "                      batch_size=32, n_parse_threads=5,\n",
    "                      shuffle_buffer_size=10000):\n",
    "    dataset = tf.data.Dataset.list_files(filenames)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filename: tf.data.TextLineDataset(filename).skip(1),\n",
    "        cycle_length=n_readers\n",
    "    )\n",
    "    # 打乱数据\n",
    "    dataset.shuffle(shuffle_buffer_size)\n",
    "    # 对dataset中的每一个item做操作\n",
    "    dataset = dataset.map(parse_csv_line, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29d652e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T08:36:29.089043Z",
     "start_time": "2022-05-30T08:36:28.893768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "tf.Tensor(\n",
      "[[ 0.48530516 -0.8492419  -0.06530126 -0.02337966  1.4974351  -0.07790658\n",
      "  -0.90236324  0.78145146]\n",
      " [ 0.4240821   0.91296333 -0.04437482 -0.15297213 -0.24727628 -0.10539167\n",
      "   0.86126745 -1.335779  ]\n",
      " [-0.66722274 -0.04823952  0.34529406  0.53826684  1.8521839  -0.06112538\n",
      "  -0.8417093   1.5204847 ]], shape=(3, 8), dtype=float32)\n",
      "y:\n",
      "tf.Tensor(\n",
      "[[2.956]\n",
      " [3.955]\n",
      " [1.59 ]], shape=(3, 1), dtype=float32)\n",
      "x:\n",
      "tf.Tensor(\n",
      "[[ 0.63636464 -1.0895426   0.09260903 -0.20538124  1.2025671  -0.03630123\n",
      "  -0.6784102   0.18223535]\n",
      " [ 0.09734604  0.75276285 -0.20218964 -0.19547    -0.40605137  0.00678553\n",
      "  -0.81371516  0.6566148 ]\n",
      " [-0.7432054   0.91296333 -0.64432025 -0.1479097   0.7398511   0.11427691\n",
      "  -0.7950524   0.68158215]], shape=(3, 8), dtype=float32)\n",
      "y:\n",
      "tf.Tensor(\n",
      "[[2.429]\n",
      " [1.119]\n",
      " [1.438]], shape=(3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 看看训练数据的效果\n",
    "train_set = csv_reader_dataset(train_filenames, batch_size=3)\n",
    "for x_batch, y_batch in train_set.take(2):\n",
    "    print('x:')\n",
    "    print(x_batch)\n",
    "    print('y:')\n",
    "    print(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdd7052d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T08:38:00.059984Z",
     "start_time": "2022-05-30T08:37:59.966768Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_set = csv_reader_dataset(train_filenames, batch_size=batch_size)\n",
    "valid_set = csv_reader_dataset(valid_filenames, batch_size=batch_size)\n",
    "test_set = csv_reader_dataset(test_filenames, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cde3bb47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T08:38:14.278031Z",
     "start_time": "2022-05-30T08:38:14.226728Z"
    }
   },
   "outputs": [],
   "source": [
    "# 模型\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=[8]),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b28d1b43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T08:43:32.149580Z",
     "start_time": "2022-05-30T08:43:00.027445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "362/362 [==============================] - 2s 3ms/step - loss: 1.5299 - mse: 1.5299 - val_loss: 0.7290 - val_mse: 0.7290\n",
      "Epoch 2/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.5930 - mse: 0.5930 - val_loss: 0.5528 - val_mse: 0.5528\n",
      "Epoch 3/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.4739 - mse: 0.4739 - val_loss: 0.4707 - val_mse: 0.4707\n",
      "Epoch 4/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.4313 - mse: 0.4313 - val_loss: 0.4410 - val_mse: 0.4410\n",
      "Epoch 5/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.4136 - mse: 0.4136 - val_loss: 0.4250 - val_mse: 0.4250\n",
      "Epoch 6/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.4004 - mse: 0.4004 - val_loss: 0.4434 - val_mse: 0.4434\n",
      "Epoch 7/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.3942 - mse: 0.3942 - val_loss: 0.4035 - val_mse: 0.4035\n",
      "Epoch 8/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.3874 - mse: 0.3874 - val_loss: 0.3947 - val_mse: 0.3947\n",
      "Epoch 9/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.3826 - mse: 0.3826 - val_loss: 0.3923 - val_mse: 0.3923\n",
      "Epoch 10/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.3819 - mse: 0.3819 - val_loss: 0.3858 - val_mse: 0.3858\n",
      "Epoch 11/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.3724 - mse: 0.3724 - val_loss: 0.3868 - val_mse: 0.3868\n",
      "Epoch 12/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.3769 - mse: 0.3769 - val_loss: 0.3815 - val_mse: 0.3815\n",
      "Epoch 13/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.3728 - mse: 0.3728 - val_loss: 0.3805 - val_mse: 0.3805\n",
      "Epoch 14/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.3687 - mse: 0.3687 - val_loss: 0.3711 - val_mse: 0.3711\n",
      "Epoch 15/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.3595 - mse: 0.3595 - val_loss: 0.3673 - val_mse: 0.3673\n",
      "Epoch 16/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.3559 - mse: 0.3559 - val_loss: 0.3645 - val_mse: 0.3645\n",
      "Epoch 17/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.3585 - mse: 0.3585 - val_loss: 0.3687 - val_mse: 0.3687\n",
      "Epoch 18/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.3507 - mse: 0.3507 - val_loss: 0.3722 - val_mse: 0.3722\n",
      "Epoch 19/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.3519 - mse: 0.3519 - val_loss: 0.3579 - val_mse: 0.3579\n",
      "Epoch 20/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.3488 - mse: 0.3488 - val_loss: 0.3576 - val_mse: 0.3576\n",
      "Epoch 21/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.3478 - mse: 0.3478 - val_loss: 0.3567 - val_mse: 0.3567\n",
      "Epoch 22/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.3520 - mse: 0.3520 - val_loss: 0.3507 - val_mse: 0.3507\n",
      "Epoch 23/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.3519 - mse: 0.3519 - val_loss: 0.3496 - val_mse: 0.3496\n",
      "Epoch 24/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.3421 - mse: 0.3421 - val_loss: 0.3468 - val_mse: 0.3468\n",
      "Epoch 25/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.3383 - mse: 0.3383 - val_loss: 0.3488 - val_mse: 0.3488\n",
      "Epoch 26/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.3441 - mse: 0.3441 - val_loss: 0.3438 - val_mse: 0.3438\n",
      "Epoch 27/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.3332 - mse: 0.3332 - val_loss: 0.3420 - val_mse: 0.3420\n",
      "Epoch 28/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.3374 - mse: 0.3374 - val_loss: 0.3378 - val_mse: 0.3378\n",
      "Epoch 29/100\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.3368 - mse: 0.3368 - val_loss: 0.3374 - val_mse: 0.3374\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=5, min_delta=1e-2)]\n",
    "# (11610, 8) (11610,)\n",
    "# (3870, 8) (3870,)\n",
    "# (5160, 8) (5160,)\n",
    "history = model.fit(train_set, \n",
    "         validation_data=valid_set,\n",
    "        # 不指定步数, 就会一直训练. \n",
    "         steps_per_epoch=11610//batch_size,\n",
    "         validation_steps=3870//batch_size,\n",
    "         epochs=100,\n",
    "         callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ad72093",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T08:44:13.726951Z",
     "start_time": "2022-05-30T08:44:13.379623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 0s 2ms/step - loss: 0.3561 - mse: 0.3561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3560712933540344, 0.3560712933540344]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set, steps=5160//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a60458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "388.85px",
    "left": "357.2px",
    "right": "20px",
    "top": "3px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
